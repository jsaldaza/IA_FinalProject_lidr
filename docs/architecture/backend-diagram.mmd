%% Backend component + sequence diagrams for TestForge (Mermaid)
%% Open this file with a Mermaid renderer (VS Code extension, mermaid.live, mermaid-cli)

%% Component diagram
flowchart LR
  FE[Frontend (Browser)] -->|POST /api/projects/create-and-start| ProjectsController[ProjectsController]
  FE -->|POST /api/projects/:id/chat| ProjectsController
  FE -->|GET /api/conversational-workflow/:id/summit| ConvController[ConversationalWorkflowController]

  ProjectsController --> WorkflowService[WorkflowService]
  ConvController --> WorkflowService
  WorkflowService --> OpenAI[OpenAIService]
  WorkflowService --> DBService[DatabaseService (Prisma)]
  DBService --> DB[(Database)]
  OpenAI -->|AI response| WorkflowService
  DBService -->|stores messages & summit| DB

%% Sequence: create-and-start

sequenceDiagram
  participant FE as Frontend
  participant PC as ProjectsController
  participant WS as WorkflowService
  participant OA as OpenAI
  participant DBS as DatabaseService

  FE->>PC: POST /api/projects/create-and-start
  PC->>WS: startConversation(projectData)
  WS->>DBS: create ConversationalAnalysis (init)
  WS->>OA: send system+user prompt
  OA-->>WS: assistant content (IA summary)
  WS->>DBS: persist assistant message
  WS->>DBS: create AnalysisSummit(refinedRequirements)
  WS-->>PC: created resources
  PC-->>FE: 200 OK + ids

%% Sequence: chat flow (user message -> AI reply)

sequenceDiagram
  participant FE2 as Frontend
  participant PC2 as ProjectsController
  participant WS2 as WorkflowService
  participant OA2 as OpenAI
  participant DBS2 as DatabaseService

  FE2->>PC2: POST /api/projects/:id/chat { instruction, requirement }
  PC2->>WS2: processUserMessage(id, normalizedContent)
  WS2->>DBS2: persist user message
  WS2->>OA2: forward messages + new content
  OA2-->>WS2: assistant reply
  WS2->>DBS2: persist assistant reply
  WS2-->>PC2: assistant reply
  PC2-->>FE2: reply (update chat)

%% End of file
